{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: typing_extensions 4.12.2\n",
      "Uninstalling typing_extensions-4.12.2:\n",
      "  Successfully uninstalled typing_extensions-4.12.2\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting typing_extensions\n",
      "  Using cached typing_extensions-4.14.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Using cached typing_extensions-4.14.0-py3-none-any.whl (43 kB)\n",
      "Installing collected packages: typing_extensions\n",
      "Successfully installed typing_extensions-4.14.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torch\n",
      "  Downloading torch-2.7.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.22.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/lautaro/.local/lib/python3.10/site-packages (from torch) (4.14.0)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in /home/lautaro/.local/lib/python3.10/site-packages (from torch) (3.1.5)\n",
      "Collecting fsspec (from torch)\n",
      "  Using cached fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch)\n",
      "  Using cached nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch)\n",
      "  Using cached nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch)\n",
      "  Using cached nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.7.77 (from torch)\n",
      "  Using cached nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch)\n",
      "  Using cached nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch)\n",
      "  Using cached nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch)\n",
      "  Using cached nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.26.2 (from torch)\n",
      "  Using cached nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.6.77 (from torch)\n",
      "  Using cached nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch)\n",
      "  Using cached nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.3.1 (from torch)\n",
      "  Downloading triton-3.3.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.10/dist-packages (from triton==3.3.1->torch) (71.1.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.0.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/lib/python3/dist-packages (from torchvision) (9.0.1)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/lautaro/.local/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading torch-2.7.1-cp310-cp310-manylinux_2_28_x86_64.whl (821.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.2/821.2 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
      "Using cached nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
      "Using cached nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
      "Using cached nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
      "Using cached nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
      "Using cached nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Downloading triton-3.3.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.6/155.6 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.22.1-cp310-cp310-manylinux_2_28_x86_64.whl (7.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Using cached fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: nvidia-cusparselt-cu12, mpmath, triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, fsspec, filelock, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision\n",
      "Successfully installed filelock-3.18.0 fsspec-2025.5.1 mpmath-1.3.0 networkx-3.4.2 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 sympy-1.14.0 torch-2.7.1 torchvision-0.22.1 triton-3.3.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall typing_extensions -y\n",
    "!pip install --upgrade typing_extensions\n",
    "\n",
    "\n",
    "!pip install torch torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagen guardada: IXI002-Guys-0828-T1_comparison.jpg\n",
      "Imagen guardada: IXI012-HH-1211-T1_comparison.jpg\n",
      "Imagen guardada: IXI013-HH-1212-T1_comparison.jpg\n",
      "Imagen guardada: IXI014-HH-1236-T1_comparison.jpg\n",
      "Imagen guardada: IXI015-HH-1258-T1_comparison.jpg\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torchvision.utils import make_grid\n",
    "import torchvision.transforms as T\n",
    "from scipy.ndimage import zoom\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "# Función para cargar y obtener cortes de una imagen NIfTI\n",
    "def load_nifti_image(nifti_path):\n",
    "    img = nib.load(nifti_path).get_fdata()\n",
    "    return img\n",
    "\n",
    "def get_slices(img):\n",
    "    \"\"\"Obtiene cortes Axial, Coronal y Sagital y los rota 90° antihorario.\"\"\"\n",
    "    # Verificar las dimensiones de la imagen\n",
    "    if len(img.shape) == 4:  # Si es 4D, tomar el primer volumen\n",
    "        img = img[..., 0]\n",
    "    elif len(img.shape) != 3:  # Si no es 3D, lanzar un error\n",
    "        raise ValueError(f\"Se esperaba una imagen 3D, pero se obtuvo una con forma {img.shape}\")\n",
    "\n",
    "    # Extraer las dimensiones\n",
    "    z, y, x = img.shape\n",
    "\n",
    "    # Obtener los cortes\n",
    "    axial = np.rot90(img[z // 2, :, :])      # Vista axial\n",
    "    coronal = np.rot90(img[:, y // 2, :])    # Vista coronal\n",
    "    sagittal = np.rot90(img[:, :, x // 2])   # Vista sagital\n",
    "\n",
    "    return axial, coronal, sagittal\n",
    "\n",
    "def normalize_image(image):\n",
    "    \"\"\" Normaliza la imagen entre 0 y 1 \"\"\"\n",
    "    return (image - np.min(image)) / (np.max(image) - np.min(image) + 1e-8)  # Evita división por cero\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "def resize_image(image, final_size=(256, 256)):\n",
    "    \"\"\"\n",
    "    Redimensiona la imagen preservando la relación de aspecto y luego aplica padding para alcanzar el tamaño final.\n",
    "    \"\"\"\n",
    "    pil_img = T.ToPILImage()(image)\n",
    "\n",
    "    # Obtener el tamaño original\n",
    "    w, h = pil_img.size  \n",
    "\n",
    "    # Calcular la escala manteniendo la proporción\n",
    "    scale = min(final_size[0] / w, final_size[1] / h)  \n",
    "    new_w, new_h = int(w * scale), int(h * scale)  \n",
    "\n",
    "    # Redimensionar con la escala correcta\n",
    "    resized = pil_img.resize((new_w, new_h), Image.BILINEAR)\n",
    "\n",
    "    # Calcular padding necesario\n",
    "    pad_left = (final_size[0] - new_w) // 2\n",
    "    pad_top = (final_size[1] - new_h) // 2\n",
    "    pad_right = final_size[0] - new_w - pad_left\n",
    "    pad_bottom = final_size[1] - new_h - pad_top\n",
    "\n",
    "    # Aplicar padding\n",
    "    transform_pad = transforms.Pad((pad_left, pad_top, pad_right, pad_bottom), fill=0)\n",
    "    padded = transform_pad(T.ToTensor()(resized))\n",
    "\n",
    "    return padded.numpy().squeeze()  # Convertimos de tensor a array\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def nifti_to_tensor(nifti_path, target_size=(256, 256)):\n",
    "    \"\"\"\n",
    "    Carga un archivo NIfTI y lo convierte en un tensor normalizado,\n",
    "    asegurando que todas las imágenes tengan el mismo tamaño.\n",
    "    \"\"\"\n",
    "    img = load_nifti_image(nifti_path)\n",
    "    axial, coronal, sagittal = get_slices(img)\n",
    "\n",
    "    # Normalizar imágenes\n",
    "    axial = normalize_image(axial)\n",
    "    coronal = normalize_image(coronal)\n",
    "    sagittal = normalize_image(sagittal)\n",
    "\n",
    "    # Redimensionar todas las imágenes al mismo tamaño\n",
    "    axial = resize_image(axial, target_size)\n",
    "    coronal = resize_image(coronal, target_size)\n",
    "    sagittal = resize_image(sagittal, target_size)\n",
    "\n",
    "    # Convertir a tensores de PyTorch (1 canal)\n",
    "    transform = T.Compose([T.ToTensor(), T.Normalize(mean=[0.5], std=[0.5])])\n",
    "    axial_t = transform(axial).unsqueeze(0)\n",
    "    coronal_t = transform(coronal).unsqueeze(0)\n",
    "    sagittal_t = transform(sagittal).unsqueeze(0)\n",
    "\n",
    "    return torch.cat([axial_t, coronal_t, sagittal_t], dim=0)\n",
    "\n",
    "def add_labels(image, subject_id):\n",
    "    \"\"\"\n",
    "    Agrega etiquetas específicas para cada fila de preprocesamiento directamente sobre cada fila en la cuadrícula.\n",
    "    \"\"\"\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Intentar cargar una fuente TrueType\n",
    "    try:\n",
    "        font_path = \"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\"  # Ruta común en sistemas Linux\n",
    "        font = ImageFont.truetype(font_path, 30)\n",
    "    except Exception as e:\n",
    "        print(f\"Error al cargar la fuente TrueType: {e}\")\n",
    "        font = ImageFont.load_default()  # Fuente por defecto si falla\n",
    "\n",
    "    W, H = image.size\n",
    "    n_rows = 5  # Número de filas en la cuadrícula\n",
    "    row_height = H // n_rows  # Altura de cada fila\n",
    "\n",
    "    # Etiquetas para cada fila\n",
    "    labels = [\"Original\", \"ANTS Rigid\", \"ANTS Affine\", \"FLIRT Rigid\", \"FLIRT Affine\"]\n",
    "\n",
    "    # Posicionar las etiquetas sobre cada fila\n",
    "    for i, label in enumerate(labels):\n",
    "        y_position = i * row_height + 10  # Posición vertical sobre cada fila\n",
    "        text_width = font.getsize(label)[0]\n",
    "        draw.text(((W - text_width) // 2, y_position), label, fill=\"red\", font=font)  # Centrado horizontalmente\n",
    "\n",
    "    # Agregar título centrado arriba\n",
    "    title = f\"{subject_id} Preprocessing Comparison\"\n",
    "    text_width = font.getsize(title)[0]\n",
    "    draw.text(((W - text_width) // 2, 5), title, fill=\"black\", font=font)\n",
    "\n",
    "    return image\n",
    "\n",
    "def plot_brain_grid(subject_id, paths, output_dir):\n",
    "    \"\"\"\n",
    "    Genera y guarda la imagen comparativa de la imagen original y los 4 preprocesamientos.\n",
    "    \"\"\"\n",
    "    # Cargar y procesar las imágenes\n",
    "    brain_slices = [nifti_to_tensor(p) for p in paths]\n",
    "    grid = make_grid(torch.cat(brain_slices, dim=0), nrow=3, padding=2, normalize=True)\n",
    "    grid_np = grid.numpy().transpose(1, 2, 0)\n",
    "\n",
    "    # Convertir a imagen de PIL y agregar etiquetas\n",
    "    img = Image.fromarray((grid_np * 255).astype(np.uint8))\n",
    "    labeled_img = add_labels(img, subject_id)\n",
    "\n",
    "    # Guardar la imagen\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_path = os.path.join(output_dir, f\"{subject_id}_comparison.jpg\")\n",
    "    labeled_img.save(output_path)\n",
    "\n",
    "# Directorios de entrada y salida\n",
    "input_dir_original = \"/data/Lautaro/Documentos/BrainAgeCOVID/DATOS/Raw_T1/datos_check_de_preprocesamiento\"\n",
    "input_dir_preproc1 = \"/data/Lautaro/Documentos/BrainAgeCOVID/DATOS/Raw_T1/datos_check_de_preprocesamiento/preprocessed_ANTS_rigid\"\n",
    "input_dir_preproc2 = \"/data/Lautaro/Documentos/BrainAgeCOVID/DATOS/Raw_T1/datos_check_de_preprocesamiento/preprocessed_ANTS_affine\"\n",
    "input_dir_preproc3 = \"/data/Lautaro/Documentos/BrainAgeCOVID/DATOS/Raw_T1/datos_check_de_preprocesamiento/preprocessed_FLIRT_rigid\"\n",
    "input_dir_preproc4 = \"/data/Lautaro/Documentos/BrainAgeCOVID/DATOS/Raw_T1/datos_check_de_preprocesamiento/preprocessed_FLIRT_affine\"\n",
    "output_dir = \"./jpeg_preprocessing_analysis_comparison\"\n",
    "\n",
    "# Obtener la lista de sujetos a procesar basado en el nombre del archivo (sin extensión) de la carpeta \"original\"\n",
    "subject_ids = [os.path.splitext(os.path.splitext(f)[0])[0]\n",
    "               for f in os.listdir(input_dir_original) if f.endswith(\".nii.gz\")]\n",
    "\n",
    "# Generar imágenes para cada sujeto\n",
    "for subject_id in subject_ids:\n",
    "    original_path = os.path.join(input_dir_original, f\"{subject_id}.nii.gz\")\n",
    "    preproc1_path = os.path.join(input_dir_preproc1, f\"{subject_id}.nii.gz\")\n",
    "    preproc2_path = os.path.join(input_dir_preproc2, f\"{subject_id}.nii.gz\")\n",
    "    preproc3_path = os.path.join(input_dir_preproc3, f\"{subject_id}.nii.gz\")\n",
    "    preproc4_path = os.path.join(input_dir_preproc4, f\"{subject_id}.nii.gz\")\n",
    "\n",
    "    if all(os.path.exists(p) for p in [original_path, preproc1_path, preproc2_path, preproc3_path, preproc4_path]):\n",
    "        plot_brain_grid(subject_id, [original_path, preproc1_path, preproc2_path, preproc3_path, preproc4_path], output_dir)\n",
    "        print(f\"Imagen guardada: {subject_id}_comparison.jpg\")\n",
    "    else:\n",
    "        print(f\"Archivos no encontrados para {subject_id}: {original_path}, {preproc1_path}, {preproc2_path}, {preproc3_path}, o {preproc4_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
