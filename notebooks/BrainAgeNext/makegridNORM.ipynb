{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: typing_extensions 4.14.0\n",
      "Uninstalling typing_extensions-4.14.0:\n",
      "  Successfully uninstalled typing_extensions-4.14.0\n",
      "Collecting typing_extensions\n",
      "  Using cached typing_extensions-4.14.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Using cached typing_extensions-4.14.0-py3-none-any.whl (43 kB)\n",
      "Installing collected packages: typing_extensions\n",
      "Successfully installed typing_extensions-4.14.0\n",
      "Requirement already satisfied: torch in ./.venv/lib/python3.10/site-packages (2.7.0)\n",
      "Requirement already satisfied: torchvision in ./.venv/lib/python3.10/site-packages (0.22.0)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.10/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.10/site-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.10/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.10/site-packages (from torch) (2025.5.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in ./.venv/lib/python3.10/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in ./.venv/lib/python3.10/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in ./.venv/lib/python3.10/site-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in ./.venv/lib/python3.10/site-packages (from torch) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in ./.venv/lib/python3.10/site-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in ./.venv/lib/python3.10/site-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in ./.venv/lib/python3.10/site-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in ./.venv/lib/python3.10/site-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in ./.venv/lib/python3.10/site-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in ./.venv/lib/python3.10/site-packages (from torch) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in ./.venv/lib/python3.10/site-packages (from torch) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in ./.venv/lib/python3.10/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in ./.venv/lib/python3.10/site-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in ./.venv/lib/python3.10/site-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.0 in ./.venv/lib/python3.10/site-packages (from torch) (3.3.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in ./.venv/lib/python3.10/site-packages (from triton==3.3.0->torch) (59.6.0)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.10/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./.venv/lib/python3.10/site-packages (from torchvision) (11.2.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall typing_extensions -y\n",
    "!pip install --upgrade typing_extensions\n",
    "\n",
    "\n",
    "!pip install torch torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagen guardada: CP0001.jpg\n",
      "Imagen guardada: CP0002.jpg\n",
      "Imagen guardada: CP0003.jpg\n",
      "Imagen guardada: CP0004.jpg\n",
      "Imagen guardada: CP0006.jpg\n",
      "Imagen guardada: CP0007.jpg\n",
      "Imagen guardada: CP0008.jpg\n",
      "Imagen guardada: CP0009.jpg\n",
      "Imagen guardada: CP0010.jpg\n",
      "Imagen guardada: CP0011.jpg\n",
      "Imagen guardada: CP0013.jpg\n",
      "Imagen guardada: CP0014.jpg\n",
      "Imagen guardada: CP0019.jpg\n",
      "Imagen guardada: CP0020.jpg\n",
      "Imagen guardada: CP0022.jpg\n",
      "Imagen guardada: CP0023.jpg\n",
      "Imagen guardada: CP0024.jpg\n",
      "Imagen guardada: CP0027.jpg\n",
      "Imagen guardada: CP0028.jpg\n",
      "Imagen guardada: CP0029.jpg\n",
      "Imagen guardada: CP0030.jpg\n",
      "Imagen guardada: CP0031.jpg\n",
      "Imagen guardada: CP0032.jpg\n",
      "Imagen guardada: CP0033.jpg\n",
      "Imagen guardada: CP0035.jpg\n",
      "Imagen guardada: CP0036.jpg\n",
      "Imagen guardada: CP0037.jpg\n",
      "Imagen guardada: CP0038.jpg\n",
      "Imagen guardada: CP0039.jpg\n",
      "Imagen guardada: CP0040.jpg\n",
      "Imagen guardada: CP0041.jpg\n",
      "Imagen guardada: CP0042.jpg\n",
      "Imagen guardada: CP0043.jpg\n",
      "Imagen guardada: CP0044.jpg\n",
      "Imagen guardada: CP0071.jpg\n",
      "Imagen guardada: CP0072.jpg\n",
      "Imagen guardada: CP0073.jpg\n",
      "Imagen guardada: CP0075.jpg\n",
      "Imagen guardada: CP0076.jpg\n",
      "Imagen guardada: CP0078.jpg\n",
      "Imagen guardada: CP0079.jpg\n",
      "Imagen guardada: CP0081.jpg\n",
      "Imagen guardada: CP0084.jpg\n",
      "Imagen guardada: CP0085.jpg\n",
      "Imagen guardada: CP0086.jpg\n",
      "Imagen guardada: CP0087.jpg\n",
      "Imagen guardada: CP0088.jpg\n",
      "Imagen guardada: CP0089.jpg\n",
      "Imagen guardada: CP0090.jpg\n",
      "Imagen guardada: CP0091.jpg\n",
      "Imagen guardada: CP0092.jpg\n",
      "Imagen guardada: CP0094.jpg\n",
      "Imagen guardada: CP0096.jpg\n",
      "Imagen guardada: CP0097.jpg\n",
      "Imagen guardada: CP0098.jpg\n",
      "Imagen guardada: CP0099.jpg\n",
      "Imagen guardada: CP0100.jpg\n",
      "Imagen guardada: CP0101.jpg\n",
      "Imagen guardada: CP0105.jpg\n",
      "Imagen guardada: CP0106.jpg\n",
      "Imagen guardada: CP0107.jpg\n",
      "Imagen guardada: CP0108.jpg\n",
      "Imagen guardada: CP0110.jpg\n",
      "Imagen guardada: CP0111.jpg\n",
      "Imagen guardada: CP0112.jpg\n",
      "Imagen guardada: CP0113.jpg\n",
      "Imagen guardada: CP0114.jpg\n",
      "Imagen guardada: CP0115.jpg\n",
      "Imagen guardada: CP0025.jpg\n",
      "Imagen guardada: CP0046.jpg\n",
      "Imagen guardada: CP0070.jpg\n",
      "Imagen guardada: CP0093.jpg\n",
      "Imagen guardada: CP0116.jpg\n",
      "Imagen guardada: CP0141.jpg\n",
      "Imagen guardada: CP0178.jpg\n",
      "Imagen guardada: CP0200.jpg\n",
      "Imagen guardada: CP0217.jpg\n",
      "Imagen guardada: CP0117.jpg\n",
      "Imagen guardada: CP0118.jpg\n",
      "Imagen guardada: CP0121.jpg\n",
      "Imagen guardada: CP0122.jpg\n",
      "Imagen guardada: CP0123.jpg\n",
      "Imagen guardada: CP0124.jpg\n",
      "Imagen guardada: CP0125.jpg\n",
      "Imagen guardada: CP0126.jpg\n",
      "Imagen guardada: CP0127.jpg\n",
      "Imagen guardada: CP0131.jpg\n",
      "Imagen guardada: CP0133.jpg\n",
      "Imagen guardada: CP0134.jpg\n",
      "Imagen guardada: CP0135.jpg\n",
      "Imagen guardada: CP0136.jpg\n",
      "Imagen guardada: CP0138.jpg\n",
      "Imagen guardada: CP0139.jpg\n",
      "Imagen guardada: CP0140.jpg\n",
      "Imagen guardada: CP0218.jpg\n",
      "Imagen guardada: CP0219.jpg\n",
      "Imagen guardada: CP0220.jpg\n",
      "Imagen guardada: CP0221.jpg\n",
      "Imagen guardada: CP0222.jpg\n",
      "Imagen guardada: CP0223.jpg\n",
      "Imagen guardada: CP0225.jpg\n",
      "Imagen guardada: CP0226.jpg\n",
      "Imagen guardada: CP0227.jpg\n",
      "Imagen guardada: CP0228.jpg\n",
      "Imagen guardada: CP0229.jpg\n",
      "Imagen guardada: CP0232.jpg\n",
      "Imagen guardada: CP0233.jpg\n",
      "Imagen guardada: CP0234.jpg\n",
      "Imagen guardada: CP0235.jpg\n",
      "Imagen guardada: CP0236.jpg\n",
      "Imagen guardada: CP0237.jpg\n",
      "Imagen guardada: CP0238.jpg\n",
      "Imagen guardada: CP0239.jpg\n",
      "Imagen guardada: CP0240.jpg\n",
      "Imagen guardada: CP0241.jpg\n",
      "Imagen guardada: CP0242.jpg\n",
      "Imagen guardada: CP0244.jpg\n",
      "Imagen guardada: CP0245.jpg\n",
      "Imagen guardada: CP0246.jpg\n",
      "Imagen guardada: CP0249.jpg\n",
      "Imagen guardada: CP0250.jpg\n",
      "Imagen guardada: CP0201.jpg\n",
      "Imagen guardada: CP0202.jpg\n",
      "Imagen guardada: CP0203.jpg\n",
      "Imagen guardada: CP0204.jpg\n",
      "Imagen guardada: CP0205.jpg\n",
      "Imagen guardada: CP0205b.jpg\n",
      "Imagen guardada: CP0206.jpg\n",
      "Imagen guardada: CP0207.jpg\n",
      "Imagen guardada: CP0208.jpg\n",
      "Imagen guardada: CP0209.jpg\n",
      "Imagen guardada: CP0210.jpg\n",
      "Imagen guardada: CP0211.jpg\n",
      "Imagen guardada: CP0212.jpg\n",
      "Imagen guardada: CP0213.jpg\n",
      "Imagen guardada: CP0214.jpg\n",
      "Imagen guardada: CP0215.jpg\n",
      "Imagen guardada: CP0216.jpg\n",
      "Imagen guardada: CP0142.jpg\n",
      "Imagen guardada: CP0143.jpg\n",
      "Imagen guardada: CP0146.jpg\n",
      "Imagen guardada: CP0147.jpg\n",
      "Imagen guardada: CP0148.jpg\n",
      "Imagen guardada: CP0149.jpg\n",
      "Imagen guardada: CP0167.jpg\n",
      "Imagen guardada: CP0168.jpg\n",
      "Imagen guardada: CP0169.jpg\n",
      "Imagen guardada: CP0170.jpg\n",
      "Imagen guardada: CP0171.jpg\n",
      "Imagen guardada: CP0172.jpg\n",
      "Imagen guardada: CP0173.jpg\n",
      "Imagen guardada: CP0174.jpg\n",
      "Imagen guardada: CP0175.jpg\n",
      "Imagen guardada: CP0176.jpg\n",
      "Imagen guardada: CP0177.jpg\n",
      "Imagen guardada: CP0048.jpg\n",
      "Imagen guardada: CP0050.jpg\n",
      "Imagen guardada: CP0052.jpg\n",
      "Imagen guardada: CP0053.jpg\n",
      "Imagen guardada: CP0054.jpg\n",
      "Imagen guardada: CP0055.jpg\n",
      "Imagen guardada: CP0056.jpg\n",
      "Imagen guardada: CP0059.jpg\n",
      "Imagen guardada: CP0060.jpg\n",
      "Imagen guardada: CP0061.jpg\n",
      "Imagen guardada: CP0062.jpg\n",
      "Imagen guardada: CP0064.jpg\n",
      "Imagen guardada: CP0065.jpg\n",
      "Imagen guardada: CP0066.jpg\n",
      "Imagen guardada: CP0067.jpg\n",
      "Imagen guardada: CP0068.jpg\n",
      "Imagen guardada: CP0069.jpg\n",
      "Imagen guardada: CP0181.jpg\n",
      "Imagen guardada: CP0182.jpg\n",
      "Imagen guardada: CP0183.jpg\n",
      "Imagen guardada: CP0185.jpg\n",
      "Imagen guardada: CP0186.jpg\n",
      "Imagen guardada: CP0187.jpg\n",
      "Imagen guardada: CP0188.jpg\n",
      "Imagen guardada: CP0189.jpg\n",
      "Imagen guardada: CP0191.jpg\n",
      "Imagen guardada: CP0192.jpg\n",
      "Imagen guardada: CP0193.jpg\n",
      "Imagen guardada: CP0194.jpg\n",
      "Imagen guardada: CP0195.jpg\n",
      "Imagen guardada: CP0196.jpg\n",
      "Imagen guardada: CP0197.jpg\n",
      "Imagen guardada: CP0198.jpg\n",
      "Imagen guardada: CP0199.jpg\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torchvision.utils import make_grid\n",
    "import torchvision.transforms as T\n",
    "from scipy.ndimage import zoom\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "# Función para cargar y obtener cortes de una imagen NIfTI\n",
    "def load_nifti_image(nifti_path):\n",
    "    img = nib.load(nifti_path).get_fdata()\n",
    "    return img\n",
    "\n",
    "def get_slices(img):\n",
    "    \"\"\"Obtiene cortes Axial, Coronal y Sagital y los rota 90° antihorario.\"\"\"\n",
    "    # Verificar las dimensiones de la imagen\n",
    "    if len(img.shape) == 4:  # Si es 4D, tomar el primer volumen\n",
    "        img = img[..., 0]\n",
    "    elif len(img.shape) != 3:  # Si no es 3D, lanzar un error\n",
    "        raise ValueError(f\"Se esperaba una imagen 3D, pero se obtuvo una con forma {img.shape}\")\n",
    "\n",
    "    # Extraer las dimensiones\n",
    "    z, y, x = img.shape\n",
    "\n",
    "    # Obtener los cortes\n",
    "    axial = np.rot90(img[z // 2, :, :])      # Vista axial\n",
    "    coronal = np.rot90(img[:, y // 2, :])    # Vista coronal\n",
    "    sagittal = np.rot90(img[:, :, x // 2])   # Vista sagital\n",
    "\n",
    "    return axial, coronal, sagittal\n",
    "\n",
    "def normalize_image(image):\n",
    "    \"\"\" Normaliza la imagen entre 0 y 1 \"\"\"\n",
    "    return (image - np.min(image)) / (np.max(image) - np.min(image) + 1e-8)  # Evita división por cero\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "def resize_image(image, final_size=(256, 256)):\n",
    "    \"\"\"\n",
    "    Redimensiona la imagen preservando la relación de aspecto y luego aplica padding para alcanzar el tamaño final.\n",
    "    \"\"\"\n",
    "    pil_img = T.ToPILImage()(image)\n",
    "\n",
    "    # Obtener el tamaño original\n",
    "    w, h = pil_img.size  \n",
    "\n",
    "    # Calcular la escala manteniendo la proporción\n",
    "    scale = min(final_size[0] / w, final_size[1] / h)  \n",
    "    new_w, new_h = int(w * scale), int(h * scale)  \n",
    "\n",
    "    # Redimensionar con la escala correcta\n",
    "    resized = pil_img.resize((new_w, new_h), Image.BILINEAR)\n",
    "\n",
    "    # Calcular padding necesario\n",
    "    pad_left = (final_size[0] - new_w) // 2\n",
    "    pad_top = (final_size[1] - new_h) // 2\n",
    "    pad_right = final_size[0] - new_w - pad_left\n",
    "    pad_bottom = final_size[1] - new_h - pad_top\n",
    "\n",
    "    # Aplicar padding\n",
    "    transform_pad = transforms.Pad((pad_left, pad_top, pad_right, pad_bottom), fill=0)\n",
    "    padded = transform_pad(T.ToTensor()(resized))\n",
    "\n",
    "    return padded.numpy().squeeze()  # Convertimos de tensor a array\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def nifti_to_tensor(nifti_path, target_size=(256, 256)):\n",
    "    \"\"\"\n",
    "    Carga un archivo NIfTI y lo convierte en un tensor normalizado,\n",
    "    asegurando que todas las imágenes tengan el mismo tamaño.\n",
    "    \"\"\"\n",
    "    img = load_nifti_image(nifti_path)\n",
    "    axial, coronal, sagittal = get_slices(img)\n",
    "\n",
    "    # Normalizar imágenes\n",
    "    axial = normalize_image(axial)\n",
    "    coronal = normalize_image(coronal)\n",
    "    sagittal = normalize_image(sagittal)\n",
    "\n",
    "    # Redimensionar todas las imágenes al mismo tamaño\n",
    "    axial = resize_image(axial, target_size)\n",
    "    coronal = resize_image(coronal, target_size)\n",
    "    sagittal = resize_image(sagittal, target_size)\n",
    "\n",
    "    # Convertir a tensores de PyTorch (1 canal)\n",
    "    transform = T.Compose([T.ToTensor(), T.Normalize(mean=[0.5], std=[0.5])])\n",
    "    axial_t = transform(axial).unsqueeze(0)\n",
    "    coronal_t = transform(coronal).unsqueeze(0)\n",
    "    sagittal_t = transform(sagittal).unsqueeze(0)\n",
    "\n",
    "    return torch.cat([axial_t, coronal_t, sagittal_t], dim=0)\n",
    "\n",
    "def add_labels(image, subject_id):\n",
    "    \"\"\"Agrega etiquetas 'Antes' y 'Después' a la izquierda y un título arriba.\"\"\"\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    \n",
    "    try:\n",
    "        font = ImageFont.truetype(\"arial.ttf\", 30)  # Intenta usar Arial\n",
    "    except:\n",
    "        font = ImageFont.load_default()  # Fuente por defecto si Arial no está disponible\n",
    "\n",
    "    W, H = image.size\n",
    "    margin = 40  # Espacio para etiquetas\n",
    "\n",
    "    # Crear una imagen más grande para incluir etiquetas\n",
    "    new_image = Image.new(\"RGB\", (W, H + margin * 2), (255, 255, 255))\n",
    "    new_image.paste(image, (0, margin))\n",
    "\n",
    "    draw = ImageDraw.Draw(new_image)\n",
    "\n",
    "    # Agregar etiquetas 'Antes' y 'Después'\n",
    "    draw.text((10, margin + H // 4), \"ANTES\", fill=\"red\", font=font)\n",
    "    draw.text((10, margin + (3 * H) // 4), \"DESPUES\", fill=\"red\", font=font)\n",
    "\n",
    "    # Agregar título centrado arriba\n",
    "    title = f\"{subject_id} DeepBrainNet Preprocessing Pipeline\"\n",
    "    text_width = draw.textbbox((0, 0), title, font=font)[2]  # Extrae solo el ancho del texto\n",
    "    draw.text(((W - text_width) // 2, 5), title, fill=\"black\", font=font)\n",
    "\n",
    "    return new_image\n",
    "\n",
    "def plot_brain_grid(subject_id, before_path, after_path, output_dir):\n",
    "    \"\"\"Genera y guarda la imagen comparativa antes y después del preprocesamiento.\"\"\"\n",
    "    brain_slices = [nifti_to_tensor(p) for p in [before_path, after_path]]\n",
    "    grid = make_grid(torch.cat(brain_slices, dim=0), nrow=3, padding=2, normalize=True)\n",
    "    grid_np = grid.numpy().transpose(1, 2, 0)\n",
    "\n",
    "    # Convertir a imagen de PIL y agregar etiquetas\n",
    "    img = Image.fromarray((grid_np * 255).astype(np.uint8))\n",
    "    labeled_img = add_labels(img, subject_id)\n",
    "\n",
    "    # Guardar la imagen\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_path = os.path.join(output_dir, f\"{subject_id}.jpg\")\n",
    "    labeled_img.save(output_path)\n",
    "\n",
    "# Directorios de entrada y salida\n",
    "input_dir_before = \"/data/Lautaro/Documentos/BrainAgeCOVID/DeepBrainNet/T1_cropped\"\n",
    "input_dir_after = \"/data/Lautaro/Documentos/BrainAgeCOVID/ADNI/ADNI_3_T1/brainagenext/preprocesedCP\"\n",
    "output_dir = \"./Preprocessing_analysis\"\n",
    "\n",
    "# Obtener la lista de sujetos a procesar basado en el nombre del archivo (sin extensión) de la carpeta \"before\"\n",
    "subject_ids = [os.path.splitext(os.path.splitext(f)[0])[0] \n",
    "               for f in os.listdir(input_dir_before) if f.endswith(\".nii.gz\")]\n",
    "\n",
    "# Generar imágenes para cada sujeto\n",
    "for subject_id in subject_ids:\n",
    "    before_path = os.path.join(input_dir_before, f\"{subject_id}.nii.gz\")\n",
    "    after_path = os.path.join(input_dir_after, f\"{subject_id}.nii.gz\")  # ahora en after, los archivos terminan en .nii.gz\n",
    "\n",
    "    if os.path.exists(before_path) and os.path.exists(after_path):\n",
    "        plot_brain_grid(subject_id, before_path, after_path, output_dir)\n",
    "        print(f\"Imagen guardada: {subject_id}.jpg\")\n",
    "    else:\n",
    "        print(f\"Archivos no encontrados para {subject_id}: {before_path} o {after_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m after_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(input_dir_after, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubject_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.nii\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmri\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcropped.nii.gz\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(before_path) \u001b[38;5;129;01mand\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(after_path):\n\u001b[0;32m---> 15\u001b[0m     plot_brain_grid(subject_id, before_path, after_path, output_dir)\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImagen guardada: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubject_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[4], line 118\u001b[0m, in \u001b[0;36mplot_brain_grid\u001b[0;34m(subject_id, before_path, after_path, output_dir)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_brain_grid\u001b[39m(subject_id, before_path, after_path, output_dir):\n\u001b[1;32m    117\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Genera y guarda la imagen comparativa antes y después del preprocesamiento.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m     brain_slices \u001b[38;5;241m=\u001b[39m [nifti_to_tensor(p) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m [before_path, after_path]]\n\u001b[1;32m    119\u001b[0m     grid \u001b[38;5;241m=\u001b[39m make_grid(torch\u001b[38;5;241m.\u001b[39mcat(brain_slices, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), nrow\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    120\u001b[0m     grid_np \u001b[38;5;241m=\u001b[39m grid\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 67\u001b[0m, in \u001b[0;36mnifti_to_tensor\u001b[0;34m(nifti_path, target_size)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;124;03mCarga un archivo NIfTI y lo convierte en un tensor normalizado,\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;124;03masegurando que todas las imágenes tengan el mismo tamaño.\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     66\u001b[0m img \u001b[38;5;241m=\u001b[39m load_nifti_image(nifti_path)\n\u001b[0;32m---> 67\u001b[0m axial, coronal, sagittal \u001b[38;5;241m=\u001b[39m get_slices(img)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Normalizar imágenes\u001b[39;00m\n\u001b[1;32m     70\u001b[0m axial \u001b[38;5;241m=\u001b[39m normalize_image(axial)\n",
      "Cell \u001b[0;32mIn[4], line 18\u001b[0m, in \u001b[0;36mget_slices\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_slices\u001b[39m(img):\n\u001b[1;32m     17\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Obtiene cortes Axial, Coronal y Sagital y los rota 90° antihorario.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m     z, y, x \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     19\u001b[0m     axial \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrot90(img[z \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m, :, :])      \u001b[38;5;66;03m# Vista axial\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     coronal \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrot90(img[:, y \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m, :])    \u001b[38;5;66;03m# Vista coronal\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "# Directorios de entrada y salida\n",
    "input_dir_before = \"/data/Lautaro/Documentos/BrainAgeCOVID/ADNI/ADNI_3_T1/sampled_imgs\"\n",
    "input_dir_after = \"/data/Lautaro/Documentos/BrainAgeCOVID/ADNI/ADNI_3_T1/freesurfer+fsl2\"\n",
    "output_dir = \"./Preprocessing_analysis\"\n",
    "\n",
    "# Obtener lista de sujetos a procesar (usar el nombre completo del archivo sin la extensión)\n",
    "subject_ids = [os.path.splitext(f)[0] for f in os.listdir(input_dir_before) if f.endswith(\".nii\")]\n",
    "\n",
    "# Generar imágenes para cada sujeto\n",
    "for subject_id in subject_ids:\n",
    "    before_path = os.path.join(input_dir_before, f\"{subject_id}.nii\")\n",
    "    after_path = os.path.join(input_dir_after, f\"{subject_id}.nii\", \"mri\", \"cropped.nii.gz\")\n",
    "\n",
    "    if os.path.exists(before_path) and os.path.exists(after_path):\n",
    "        plot_brain_grid(subject_id, before_path, after_path, output_dir)\n",
    "        print(f\"Imagen guardada: {subject_id}.jpg\")\n",
    "    else:\n",
    "        print(f\"Archivos no encontrados para {subject_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de la imagen NIfTI: (167, 212, 160)\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "\n",
    "# Ruta al archivo NIfTI\n",
    "ruta_imagen = '/data/Lautaro/Documentos/BrainAgeCOVID/ADNI/ADNI_3_T1/IXI/freesurfer+fsl(IXI)/IXI013-HH-1212-T1/mri/cropped.nii.gz'  # Modifica esta ruta\n",
    "\n",
    "# Cargar la imagen\n",
    "img = nib.load(ruta_imagen)\n",
    "\n",
    "# Obtener el array de datos\n",
    "data = img.get_fdata()\n",
    "\n",
    "# Mostrar el tamaño (dimensiones) de la imagen\n",
    "print(\"Tamaño de la imagen NIfTI:\", data.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
